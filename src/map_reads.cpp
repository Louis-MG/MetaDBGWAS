/*
## Copyright (C) <2017>  <bioMerieux, Universite Claude Bernard Lyon 1,
## Centre National de la Recherche Scientifique>

## 1. This program is free software: you can redistribute it and/or modify
## it under the terms of the GNU Affero General Public License as published
## by the Free Software Foundation version 3 of the  License and under the
## terms of article 2 below.
## 2. This program is distributed in the hope that it will be useful, but
## WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
## or FITNESS FOR A PARTICULAR PURPOSE. See below the GNU Affero General
## Public License for more details.
## You should have received a copy of the GNU Affero General Public License
## along with this program.  If not, see <http://www.gnu.org/licenses/>.
## 3. Communication to the public by any means, in particular in the form of
## a scientific paper, a poster, a slideshow, an internet page, or a patent,
## of a result obtained directly or indirectly by running this program must
## cite the following paper :
##  Magali Jaillard, Maud Tournoud, Leandro Lima, Vincent Lacroix,
##  Jean-Baptiste Veyrieras and Laurent Jacob, "Representing Genetic
##  Determinants in Bacterial GWAS with Compacted De Bruijn Graphs", 2017,
##  Cold Spring Harbor Labs Journals, doi:10.1101/113563.
##  (url: http://www.biorxiv.org/content/early/2017/03/03/113563)
## -------------------------------------------------------------------------

## Authors (alphabetically): Jacob L., Jaillard M., Lima L.
*/

#include "global.h"
#include "map_reads.hpp"
#include "Utils.h"
#include "PhenoCounter.h"
#include <boost/algorithm/string/predicate.hpp>
#include <boost/archive/text_oarchive.hpp>
#include <map>
#define NB_OF_READS_NOTIFICATION_MAP_AND_PHASE 10 //Nb of reads that the map and phase must process for notification
using namespace std;


void mapReadToTheGraphCore(const string &read, const Graph &graph, const vector< UnitigIdStrandPos > &nodeIdToUnitigId,
                           map<int,int> &unitigIdToCount) {
    int lastUnitig=-1;

    //goes through all nodes/kmers of the read
    if (read.size() >= graph.getKmerSize()) {
        for (int i = 0; i < read.size() - graph.getKmerSize() + 1; i++) {
            string LRKmer = string(read.c_str() + i, graph.getKmerSize());

            //TODO: From my tests, if you use buildNode with a Kmer containing an 'N', it will build a node with all Ns replaced by G
            //TODO: However, Kmers containing Ns are NOT included in any unitig (i.e. the graph builder does not convert an N to a G, and build the graph. It simply disregards kmers containing Ns)
            //TODO: this is a sanity check to also discard Kmers containing Ns
            //TODO: check this with GATB team

            //TODO: UPDATE
            //TODO: Magali had a dataset where we had the base 'K' in the fasta file
            //TODO: So I am just discarding all reads that are not composed by ACGT
            if (!boost::all(LRKmer, [](char c) -> bool {
                return c=='A' || c=='a' || c=='C' || c=='c' || c=='G' || c=='g' ||c=='T' || c=='t';
            })) {
                continue;
            }



            //build the node
            Node node = graph.buildNode(LRKmer.c_str());

            //get the unitig localization of this kmer
            u_int64_t index = graph.nodeMPHFIndex(node);
            if (index == ULONG_MAX ) {
                cerr << "The kmer" << LRKmer << "was not found in the graph." << endl ; //to make it easier to use and debug in the future
                abort();
            }
            //TODO: several LRKmers are not in the unitig graph. no clue why.
            //TODO: UPDATE
            //TODO: got my clue: bcalm has default setting to minimum abundance of kmers set to 2 for consideration when building unitigs, so 44M kmers where ignored pon test file of 50M.
            //TODO: have to find what to do with that info. Since Lighter corrected the reads maybe we are good with -abundance-min 1.
            //TODO : UPDATE : we keep -abundance-min to 1
            UnitigIdStrandPos unitigIdStrandPos=nodeIdToUnitigId[index]; //TODO: find problem. See email for screenshots.
            // from the comment in Graph.hpp of gatb core, if ULONG_MAX is outputed
            // thus a node is not in the graph.

            if (lastUnitig != unitigIdStrandPos.unitigId) {
                if (unitigIdToCount.find(unitigIdStrandPos.unitigId) == unitigIdToCount.end() )
                    unitigIdToCount[unitigIdStrandPos.unitigId]=0;
                unitigIdToCount[unitigIdStrandPos.unitigId]++;
                lastUnitig = unitigIdStrandPos.unitigId;
            }
        }
    }
}

void mapReadToTheGraph(const string &read, int readfileIndex, unsigned long readIndex, const Graph &graph,
                       const vector< UnitigIdStrandPos > &nodeIdToUnitigId, map<int,int> &unitigIdToCount) {
    //map the read
    mapReadToTheGraphCore(read, graph, nodeIdToUnitigId, unitigIdToCount);
}


// We define a functor that will be cloned by the dispatcher
struct MapAndPhase
{
    const vector<string> &allReadFilesNames;
    const Graph& graph;
    const string &outputFolder;
    const string &tmpFolder;
    uint64_t &nbOfReadsProcessed;
    ISynchronizer* synchro;
    vector< UnitigIdStrandPos > &nodeIdToUnitigId;
    int nbContigs;

    struct MapAndPhaseIteratorListener : public IteratorListener {
        uint64_t &nbOfReadsProcessed;
        ISynchronizer* synchro;
        MapAndPhaseIteratorListener(uint64_t &nbOfReadsProcessed, ISynchronizer* synchro) :
            nbOfReadsProcessed(nbOfReadsProcessed), synchro(synchro){}

        virtual void inc (u_int64_t ntasks_done) {
            // We lock the synchronizer
            synchro->lock ();

            nbOfReadsProcessed+=NB_OF_READS_NOTIFICATION_MAP_AND_PHASE;
            cerr << '\r' << nbOfReadsProcessed << " reads processed.";
            cerr.flush();

            // We unlock the synchronizer
            synchro->unlock ();
        }
    };

    MapAndPhase (const vector<string> &allReadFilesNames, const Graph& graph,
                 const string &outputFolder, const string &tmpFolder, uint64_t &nbOfReadsProcessed, ISynchronizer* synchro,
                 vector< UnitigIdStrandPos > &nodeIdToUnitigId, int nbContigs) :
        allReadFilesNames(allReadFilesNames), graph(graph), outputFolder(outputFolder), tmpFolder(tmpFolder),
        nbOfReadsProcessed(nbOfReadsProcessed), synchro(synchro), nodeIdToUnitigId(nodeIdToUnitigId),
        nbContigs(nbContigs){}

    void operator()(int i) {
        // We declare an input Bank and use it locally
        IBank *inputBank = Bank::open(allReadFilesNames[i]);
        LOCAL(inputBank);

        // Create and use a progress iterator
        MapAndPhaseIteratorListener* mapAndPhaseIteratorListener = new MapAndPhaseIteratorListener(nbOfReadsProcessed, synchro);
        SubjectIterator <Sequence> it(inputBank->iterator(), NB_OF_READS_NOTIFICATION_MAP_AND_PHASE, mapAndPhaseIteratorListener);

        //XU_strain_i = how many times each unitig map to a strain
        ofstream mappingOutputFile;
        openFileForWriting(tmpFolder+string("/XU_strain_")+to_string(i), mappingOutputFile);

        // We loop over sequences.
        unsigned long readIndex = 0;
        map<int,int> unitigIdToCount;
        for (it.first(); !it.isDone(); it.next()) {
            string read = (it.item()).toString();
            //transform the read to upper case
            for (int j=0;j<read.size();j++)
                read[j]=toupper(read[j]);

            //map this read to the graph
            mapReadToTheGraph(read, i, readIndex, graph, nodeIdToUnitigId, unitigIdToCount);

            readIndex++;
        }

        //output info for mapping - the number of times the unitig appear in the strain
        for (int i=0;i<nbContigs;i++) {
            if (unitigIdToCount.find(i) == unitigIdToCount.end() )
                mappingOutputFile << "0 ";
            else
                mappingOutputFile << unitigIdToCount[i] << " ";
        }

        mappingOutputFile.close();
    }
};

/*********************************************************************
** METHOD  :
** PURPOSE :
** INPUT   :
** OUTPUT  :
** RETURN  :
** REMARKS :
*********************************************************************/
// The Tool constructor allows to give a name to our tool.
// This name appears when one gets help in the command line or in the final output
map_reads::map_reads ()  : Tool ("map_reads") //give a name to our tool
{
    populateParser(this);
}

//pattern is the unitig line
map< vector<int>, vector<int> > getUnitigsWithSamePattern (const vector< vector<int> > &XU, int nbContigs) {
    map< vector<int>, vector<int> > pattern2Unitigs;

    for (int i=0;i<XU.size();i++) { //goes through all unitigs
        if (pattern2Unitigs.count(XU[i])==0) { //pattern of unitig i is not in pattern2Unitigs
            //create a vector with unitig i
            vector<int> unitigs;
            unitigs.push_back(i);

            //insert this pattern and his new set to the map
            pattern2Unitigs.insert(make_pair(XU[i], unitigs));
        } else {
            //pattern of unitig i is already in pattern2Unitigs, just add
            pattern2Unitigs[XU[i]].push_back(i);
        }
    }

    return pattern2Unitigs;
}

void generate_XU(const string &filename, const vector< vector<int> > &XU) {
    ofstream XUFile;
    openFileForWriting(filename, XUFile);

    //print the header
    XUFile << "ps";
    for (const auto &strain : (*strains))
        XUFile << " " << strain.id;
    XUFile << endl;

    for (int i=0;i<XU.size();i++) {
        //print the unitig id
        XUFile << (i);

        //print the frequences/binaries
        for (int j=0;j<XU[i].size();j++)
            XUFile << " " << XU[i][j];
        XUFile << endl;
    }
    XUFile.close();
}


void generate_unique_id_to_original_ids(const string &uniqueIdToOriginalIdsFilename,
                                        const string &gemmaPatternToNbUnitigsFilename,
                                        const string &gemmaUnitigToPatternFilename,
                                        const map< vector<int>, vector<int> > &pattern2Unitigs) {
    ofstream uniqueIdToOriginalIdsFile;
    openFileForWriting(uniqueIdToOriginalIdsFilename, uniqueIdToOriginalIdsFile);
    ofstream gemmaPatternToNbUnitigsFile;
    openFileForWriting(gemmaPatternToNbUnitigsFilename, gemmaPatternToNbUnitigsFile);
    ofstream gemmaUnitigToPatternFile;
    openFileForWriting(gemmaUnitigToPatternFilename, gemmaUnitigToPatternFile);

    //for each pattern
    int i=0;
    auto it=pattern2Unitigs.begin();
    for (;it!=pattern2Unitigs.end();++it, ++i) {
        //goes through the unitigs of this file
        for (auto id : it->second) {
            //uniqueIdToOriginalIdsFile
            //print all the unitigs of a pattern i in line i
            uniqueIdToOriginalIdsFile << id << " ";
            //uniqueIdToOriginalIdsFile

            //gemmaUnitigToPatternFile
            gemmaUnitigToPatternFile << id << " " << i << endl;
            //gemmaUnitigToPatternFile
        }
        uniqueIdToOriginalIdsFile << endl;
        //uniqueIdToOriginalIdsFile



        //gemmaPatternToNbUnitigsFile
        gemmaPatternToNbUnitigsFile << i << " " << (it->second).size() << endl;
        //gemmaPatternToNbUnitigsFile
    }

    uniqueIdToOriginalIdsFile.close();
    gemmaPatternToNbUnitigsFile.close();
    gemmaUnitigToPatternFile.close();
}

void generate_XU_unique(const string &filename, const vector< vector<int> > &XU,
                        const map< vector<int>, vector<int> > &pattern2Unitigs){
    ofstream XUUnique;
    openFileForWriting(filename, XUUnique);

    //print the header
    XUUnique << "ps";
    for (const auto &strain : (*strains))
        XUUnique << " " << strain.id;
    XUUnique << endl;

    //for each pattern
    int i=0;
    auto it=pattern2Unitigs.begin();
    for (;it!=pattern2Unitigs.end();++it, ++i) {
        //print the id of this pattern
        XUUnique << i;

        //print the pattern
        for (const auto &v : it->first)
            XUUnique << " " << v;
        XUUnique << endl;
    }
    XUUnique.close();
}

//TODO: this part can be replaced with loading of the REINDEER matrix
//generate the bugwas input
void generateBugwasInput (const vector <string> &allReadFilesNames, const string &outputFolder, const string &tmpFolder, int nbContigs) {
    //Generate the XU (the bugwas input - the matrix where the unitigs are rows and the strains are columns)
    //XU_unique is XU with the duplicated rows removed
    cerr << endl << endl << "[Generating bugwas and gemma input]..." << endl;

    //create the ID and Phenotype file
    Strain::createIdPhenoFile(outputFolder+string("/bugwas_input.id_phenotype"), strains);

    //Create XU
    vector< vector<int> > XU(nbContigs);
    for (auto & v : XU)
        v.resize(allReadFilesNames.size());

    //populate XU
    for (int j=0; j<allReadFilesNames.size(); j++) {
        ifstream inputFile;
        openFileForReading(tmpFolder+string("/XU_strain_")+to_string(j), inputFile);
        for (int i = 0; i < nbContigs; i++)
            inputFile >> XU[i][j];
        inputFile.close();
    }

    //create a binary XU
    //TODO [CONTINUOUS GENOTYPE] : no need for this -> if it is binary, the counts are already as 0/1
    //TODO [CONTINUOUS GENOTYPE] : if it is not, it is the true count
    //TODO [CONTINUOUS GENOTYPE] : removing this will also save a lot of memory
    vector< vector<int> > XUbinary(XU);

    //creates also a file saying if the unitig was inverted (-1) or not (1)
    //this is a multiplicative factor that will correct the weight (estimated effect) from the statistical test
    ofstream weightCorrectionStream;
    openFileForWriting(outputFolder+string("/weight_correction"), weightCorrectionStream);

    for (int i=0;i<XUbinary.size();i++) {
        //1. Transform frequency to binary
        for (int j = 0; j < XUbinary[i].size(); j++)
            XUbinary[i][j] = ((int)((bool)(XUbinary[i][j])));

        //2. Transform to the encoding where 0 is the major allele and 1 is the minor one
        //count how many 0s and 1s we have
        int count0=0;
        int count1=0;
        for (int j=0;j<XUbinary[i].size();j++) {
            if (XUbinary[i][j]==0) count0++;
            if (XUbinary[i][j]==1) count1++;
        }

        //0 must be the major allele (we need to have more 0s than 1s). If it is not, 0 and 1 must be inverted
        int iMustInvert = ((int)(count0 < count1));

        //re-assign the values to XUbinary
        for (int j=0;j<XUbinary[i].size();j++)
            XUbinary[i][j] = ((XUbinary[i][j]+iMustInvert)%2);

        weightCorrectionStream << (iMustInvert ? -1 : 1) << endl;
    }
    weightCorrectionStream.close();

    //create the files for bugwas
    /*
     * TODO: THIS IS NOT CREATED RIGHT NOW BECAUSE WE CANNOT PROCESS IT - BUGWAS, FOR THE MOMENT, JUST ACCEPT THE 0/1 (BINARY) FILES
     * TODO: PUT THIS BACK WHEN WE ARE ABLE TO DO IT
     * TODO: IF THE COUNT MODE IS FREQ, ONLY THE BINARY VERSION IS USED FOR BUGWAS - FIX THIS
    {
        generate_XU(outputFolder+string("/bugwas_input.all_rows.frequency"), XU);
        map< vector<int>, vector<int> > pattern2Unitigs = getUnitigsWithSamePattern(XU, nbContigs);
        generate_unique_id_to_original_ids(outputFolder+string("/bugwas_input.unique_rows_to_all_rows.frequency"), pattern2Unitigs);
        generate_XU_unique(outputFolder+string("/bugwas_input.unique_rows.frequency"), XU, pattern2Unitigs);
    }
     */

    //create the files for bugwas - binary ones
    {
        generate_XU(outputFolder+string("/bugwas_input.all_rows.binary"), XUbinary);
        map< vector<int>, vector<int> > pattern2Unitigs = getUnitigsWithSamePattern(XUbinary, nbContigs);
        generate_unique_id_to_original_ids(outputFolder+string("/bugwas_input.unique_rows_to_all_rows.binary"),
                                           outputFolder+string("/gemma_input.pattern_to_nb_of_unitigs.binary"),
                                           outputFolder+string("/gemma_input.unitig_to_pattern.binary"),
                                           pattern2Unitigs);
        generate_XU_unique(outputFolder+string("/bugwas_input.unique_rows.binary"), XUbinary, pattern2Unitigs); //TODO: c'est ici que des XU sont utilises
    }
    cerr << "[Generating bugwas and gemma input] - Done!" << endl;


    // create a vector indexed by the unitigIndex containing each position a vector of phenotypeValue,
    // indicating the phenotypes of each appearance of the unitig in the strains
    // it can be used to know the total count of a unitig (size of the vector) and their phenotype count in step 3
    // (e.g. how many times an unitig appeared in strains with phenotype 0, >0 and NA)
    //TODO: instead of representing the phenotype of each appearance, just use a pair <count, phenotype>
    //TODO: this could save disk
    cerr << "[Generating unitigs2PhenoCounter...]" << endl;
    vector< PhenoCounter > unitigs2PhenoCounter(nbContigs);
    for(int strainIndex=0;strainIndex<allReadFilesNames.size();strainIndex++) {
        ifstream unitigCountForStrain;
        openFileForReading(tmpFolder+string("/XU_strain_")+to_string(strainIndex), unitigCountForStrain);
        for (int unitigIndex=0; unitigIndex<nbContigs; unitigIndex++) {
            int count;
            unitigCountForStrain >> count;
            unitigs2PhenoCounter[unitigIndex].add((*strains)[strainIndex].phenotype, count);
        }
        unitigCountForStrain.close();
    }

    //serialize unitigs2PhenoCounter
    {
        ofstream unitigs2PhenoCounterFile;
        openFileForWriting(outputFolder+string("/unitigs2PhenoCounter"), unitigs2PhenoCounterFile);
        boost::archive::text_oarchive boostOutputArchive(unitigs2PhenoCounterFile);
        //serialization itself
        boostOutputArchive & unitigs2PhenoCounter;
    } //boostOutputArchive and the stream are closed on destruction

    Strain::createPhenotypeCounter(outputFolder+string("/phenoCounter"), strains);
    cerr << "[Generating unitigs2PhenoCounter...] - Done!" << endl;
}

/*********************************************************************
** METHOD  :
** PURPOSE : executes map_reads
** INPUT   : output folder name, unitigs
** OUTPUT  : bugwas_input.* files (4) and weight_correction file
** RETURN  :
** REMARKS : deletes graph, NodeIdToUnitigs obects as well as the tmpFolder
*********************************************************************/
void map_reads::execute ()
{
    //populates strains file if given
    checkParametersMapping(this);

    //get the parameters
    int nbCores = getInput()->getInt(STR_NBCORES);
    string referenceOutputFolder = getInput()->getStr(STR_OUTPUT); //keep the original output folder in a variable for file manipulation
    string outputFolder = stripLastSlashIfExists(getInput()->getStr(STR_OUTPUT))+string("/step1");
    string tmpFolder = outputFolder+string("/tmp");
    //create the tmp folder of step1
    createFolder(tmpFolder);

    //create the reads file
    string readsFile(tmpFolder+string("/readsFile"));
    Strain::createReadsFile(readsFile, strains);

    string longReadsFile = tmpFolder+string("/readsFile");

    //get the nbContigs
    int nbContigs = getNbLinesInFile(referenceOutputFolder + string("/graph.nodes"));


    // Finding the unitigs
    //nodeIdToUnitigId translates the nodes that are stored in the GATB graph to the id of the unitigs together with the unitig strand
    //orioginaly intilised in build_dbg.cpp line 271
    nodeIdToUnitigId = new vector< UnitigIdStrandPos >((size_t)graph->getInfo()["kmers_nb_solid"]->getInt());

    //Do the Mapping
    //Maps all the reads back to the graph

    //get all the read files' name
    vector <string> allReadFilesNames = getVectorStringFromFile(longReadsFile);

    // We create an iterator over an integer range
    Range<int>::Iterator allReadFilesNamesIt(0, allReadFilesNames.size() - 1);

    //synchronizer object
    ISynchronizer *synchro = System::thread().newSynchronizer();

    // We create a dispatcher configured for 'nbCores' cores.
    Dispatcher dispatcher(nbCores, 1);

    cerr << "[Starting mapping process... ]" << endl;
    cerr << "Using " << nbCores << " cores to map " << allReadFilesNames.size() << " read files." << endl;

    // We iterate the range.  NOTE: we could also use lambda expression (easing the code readability)
    uint64_t nbOfReadsProcessed = 0;
    dispatcher.iterate(allReadFilesNamesIt,
                       MapAndPhase(allReadFilesNames, *graph, outputFolder, tmpFolder, nbOfReadsProcessed, synchro,
                                   *nodeIdToUnitigId, nbContigs));

    //generate the bugwas input
    generateBugwasInput(allReadFilesNames, outputFolder, tmpFolder, nbContigs);

    //after the mapping, free some memory that will not be needed anymore
    delete graph;
    delete nodeIdToUnitigId;

    //clean-up - saving some disk space
    //remove temp directory
    boost::filesystem::remove_all(tmpFolder);
    //remove GATB's graph file
    remove((referenceOutputFolder+string("/graph.h5")).c_str());

    cerr << endl << "[Mapping process finished!]" << endl;
    cerr.flush();
}
